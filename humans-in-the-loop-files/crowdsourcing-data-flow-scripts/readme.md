# Crowdsourcing Data Flow Scripts
Scripts for uploading input images to Scribe and exporting data to the workflow database. To use with the HITL Scribe installation, move this folder below the scribe-hitl directory.   

## CS 1 - dataflow/CS1.py
This script pulls page images and relevant metadata from the workflow database and outputs CSV files of page subjects for ingest into Scribe Workflow 1. It is assumed that individual page coordinates will have been generated by the page detection algorithm and written to the Data_Source table for each digital object listed in the items
variable.  
- Get source urls for individual images from the IIIF manifest for each item and writing to the source_url column of the Data_Source table for each digital object image.
- Get metadata from Data_Source table for pages in each item
- Generate the IIIF image url for each based on page image coordinates and write to Data_Source table
- Output CSV files for each item and a CSV file with all items and item-level metadata to the Workflow 1 /subjects
directory

## CS 2 - dataflow/CS2.py
This script pulls completed subjects from the Scribe MongoDB for Workflow 1 into the /exports folder, writes these annotations and coordinates to the workflow database, creates IIIF URLs for business groupings and adds them to the Data_Source table, then pulls relevant metadata from the workflow database and outputs CSV files of business grouping subjects for ingest into Scribe Workflow 2.
- Pull down subjects from MongoDB for Workflow 1
- Write advertisement, business grouping, and telephone tips annotations to the Annotation and Coordinates tables
- Write business grouping data to Data_Source table (including new IIIF image urls) for use in Workflow 2
- Get metadata from Data_Source table for business groupings in each item
- Output CSV files with business groupings for each item and a CSV file with all items and item-level metadata to the Workflow 2 /subjects directory

## CS 3 - dataflow/CS3.py
This script pulls completed subjects from the Scribe MongoDB for Workflow 2 into the /exports folder, writes these annotations, coordinates, and text to the workflow database, adds business listings to the Data_Source table, then pulls relevant metadata from the workflow database and outputs CSV files of business listing subjects for ingest into Scribe Workflow 3.
- Pull down subjects from MongoDB for Workflow 2
- Write business type and listing annotations to the Annotation, Coordinates, and Text_Value tables
- Write business listing data to Data_Source table (including new IIIF image urls) for use in Workflow 3
- Get metadata from Data_Source table for business listings in each item
- Output CSV files with business listings for each item and a CSV file with all items and item-level metadata to the Workflow 3 /subjects directory

## CS 4 - dataflow/CS4.py
This script pulls completed subjects from the Scribe MongoDB for Workflow 3 into the /exports folder, and writes these annotations, coordinates, and text to the workflow database. This data can be used to create training data for the CRF NLP machine learning process or as ground truth for the output of that process.
- Pull down subjects from MongoDB for Workflow 3
- Write business entity annotations to the Annotation, Coordinates, and Text_Value tables

## Creating training data - dataflow/create_ML5_training_data.py
This script pulls business entity data from the workflow database and generates markdown files for use as training data in the CRF NLP process. (See sample training data in /training)
- Get crowdsourced business listing entities from workflow database
- For each business listing sort entities by bounding coordinates into reading order
- Format and output data as markdown (with entity labels as "links" for entities) for training